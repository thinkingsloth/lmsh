# lmsh Configuration
# Copy this file to .env and fill in your values

# =============================================================================
# OpenAI (Default)
# =============================================================================
LMSH_API_TOKEN=sk-your-openai-api-key-here
LMSH_MODEL_ID=gpt-4o
# LMSH_BASE_URL is optional for OpenAI (defaults to https://api.openai.com/v1)

# =============================================================================
# Claude (Anthropic)
# =============================================================================
# LMSH_BASE_URL=https://api.anthropic.com/v1
# LMSH_API_TOKEN=sk-ant-your-anthropic-key-here
# LMSH_MODEL_ID=claude-opus-4-20250514

# =============================================================================
# Local vLLM Server
# =============================================================================
# LMSH_BASE_URL=http://127.0.0.1:8000/v1
# LMSH_API_TOKEN=dummy
# LMSH_MODEL_ID=your-local-model-name

# =============================================================================
# Optional Settings
# =============================================================================
# Output Format (bash, sh, zsh, python, python3, node, ruby, perl)
# LMSH_OUTPUT=bash

# Allow Sudo Commands (true/false)
# LMSH_ALLOW_SUDO=false
